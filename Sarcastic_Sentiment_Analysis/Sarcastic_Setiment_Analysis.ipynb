{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d119e909",
   "metadata": {},
   "source": [
    "### Build a sequential NLP classifier which can use input text parameters to determine the customer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7de8e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Activation, Bidirectional, LSTM, Dense, Dropout, Flatten, Input\n",
    "from functools import partial\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5e9f9",
   "metadata": {},
   "source": [
    "#### 1. Read and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92a2d5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>https://politics.theonion.com/epa-chief-pruitt...</td>\n",
       "      <td>epa chief pruitt welcomes delegation of pollut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>https://www.theonion.com/skittish-juniors-depa...</td>\n",
       "      <td>skittish juniors-department clerk calls securi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/unions-pl...</td>\n",
       "      <td>unions plot major push after landmark labor ru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>https://politics.theonion.com/poll-89-of-ameri...</td>\n",
       "      <td>poll: 89% of americans believe obama has faile...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22501</th>\n",
       "      <td>https://www.theonion.com/401k-enrollment-form-...</td>\n",
       "      <td>401k enrollment form sits at bottom of desk dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_link  \\\n",
       "1741   https://politics.theonion.com/epa-chief-pruitt...   \n",
       "10438  https://www.theonion.com/skittish-juniors-depa...   \n",
       "2160   https://www.huffingtonpost.com/entry/unions-pl...   \n",
       "13896  https://politics.theonion.com/poll-89-of-ameri...   \n",
       "22501  https://www.theonion.com/401k-enrollment-form-...   \n",
       "\n",
       "                                                headline  is_sarcastic  \n",
       "1741   epa chief pruitt welcomes delegation of pollut...             1  \n",
       "10438  skittish juniors-department clerk calls securi...             1  \n",
       "2160   unions plot major push after landmark labor ru...             0  \n",
       "13896  poll: 89% of americans believe obama has faile...             1  \n",
       "22501  401k enrollment form sits at bottom of desk dr...             1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d472bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_link  26709 non-null  object\n",
      " 1   headline      26709 non-null  object\n",
      " 2   is_sarcastic  26709 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 626.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89bca03",
   "metadata": {},
   "source": [
    "Expected data is loaded in notebook. \n",
    "Important columns as per problem statement are \"headline\" and \"is_sarcastic\".\n",
    "All columns are having values, count of records is 26k+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b68f0d",
   "metadata": {},
   "source": [
    "#### 2. Retain relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3fdbce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eleminate rest of the non-important columns\n",
    "df.drop(['article_link'], axis =1, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b98f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c26ae8",
   "metadata": {},
   "source": [
    "#### 3. Get length for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e690fc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        78\n",
       "1        84\n",
       "2        79\n",
       "3        84\n",
       "4        64\n",
       "         ..\n",
       "26704    36\n",
       "26705    23\n",
       "26706    21\n",
       "26707    60\n",
       "26708    33\n",
       "Name: headline, Length: 26709, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc81de7",
   "metadata": {},
   "source": [
    "This share us length of each sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8471115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26709.000000\n",
       "mean        60.910592\n",
       "std         19.184470\n",
       "min          7.000000\n",
       "25%         48.000000\n",
       "50%         61.000000\n",
       "75%         73.000000\n",
       "max        254.000000\n",
       "Name: headline, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874c412",
   "metadata": {},
   "source": [
    "This length is including spaces in a sentances, we need to calculate without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "013f2048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26709.000000\n",
       "mean         9.847842\n",
       "std          3.172099\n",
       "min          2.000000\n",
       "25%          8.000000\n",
       "50%         10.000000\n",
       "75%         12.000000\n",
       "max         39.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'] = df['headline'].apply(lambda x:len(x.split(\" \")))\n",
    "df['len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd0b1b",
   "metadata": {},
   "source": [
    "We have max 39 words length with this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4481f",
   "metadata": {},
   "source": [
    "#### 4. Define parameters [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe50c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 30\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8cc18",
   "metadata": {},
   "source": [
    "Set the parameters for word embedding and feature count.\n",
    "It a trail approach to reach results with optimum usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b2eca",
   "metadata": {},
   "source": [
    "#### 5. Get indices for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7165b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 26709\n",
      "[307, 678, 3336, 2297, 47, 381, 2575, 5, 2576, 8433]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(df['headline']))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['headline'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))       \n",
    "print(X[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba5ae7",
   "metadata": {},
   "source": [
    "#### 6. Create features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d215d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels:  26709\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#pad sequence to have equal length of sentences picked for processing\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Labels: \", len(y))   \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfcaa4",
   "metadata": {},
   "source": [
    "#### 7. Get vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1f09f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b9ab77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29657\n"
     ]
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2e0a9",
   "metadata": {},
   "source": [
    "#### 8. Create a weight matrix using GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a414c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'glove.6B.50d.txt'\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE,  'r', encoding='utf-8'):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "282d53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words, 50))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d71848b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "print (len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b63d95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29657, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "020b5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 50, stratify=y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f934965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18696, 30) (8013, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc619287",
   "metadata": {},
   "source": [
    "#### 9. Define and compile a Bidirectional LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11afb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model():\n",
    "    # create model\n",
    "    inputs = Input(name='inputs',shape=[maxlen])\n",
    "    layer = Embedding(num_words,50,input_length=maxlen,  weights = [embedding_matrix])(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(128,name='Features')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Activation('LeakyReLU')(layer)\n",
    "    layer = Dense(1,name='Out')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d71236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8ec20",
   "metadata": {},
   "source": [
    "#### 10. Fit the model and check the validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b296b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eea400bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 30)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 30, 50)            1482850   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " Features (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " Out (Dense)                 (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,520,739\n",
      "Trainable params: 1,520,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d86d3e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "147/147 [==============================] - 8s 45ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 2/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 3/15\n",
      "147/147 [==============================] - 6s 44ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 4/15\n",
      "147/147 [==============================] - 6s 43ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 5/15\n",
      "147/147 [==============================] - 6s 43ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 6/15\n",
      "147/147 [==============================] - 6s 43ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 7/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 8/15\n",
      "147/147 [==============================] - 6s 41ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 9/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 10/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 11/15\n",
      "147/147 [==============================] - 6s 42ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 12/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 13/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 14/15\n",
      "147/147 [==============================] - 6s 43ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n",
      "Epoch 15/15\n",
      "147/147 [==============================] - 6s 40ms/step - loss: nan - accuracy: 0.5610 - val_loss: nan - val_accuracy: 0.5611\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "training_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120cbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
